\section{Compensating for Overcounts}
Now that we have determined the factors causing non-determinism
and overcount, we investigate if it may be possible to compensate for
the limitations and derive deterministic events where there are none.

Overcount on its own does not provide a problem for applications
such as deterministic locking.
The run-to-run counts will be the same,
just different from the expected value.  
This is only a problem if applying results gathered on one 
machine to runs on a different one with different level of overcounts.  
In this case adjusted results
can be generated if the exact opcode mix of a program is known; this
is usually not possible without extra analysis by an external tool
and in general not possible to determine in real time.

Compensating for non-determinism is a more difficult problem.
When measuring aggregate totals, a compensation factor can
be subtracted at the end of a run.
For events that include hardware interrupts, corrected counts can be 
generated by measuring a hardware interrupt event (if available)
and adjusting the total by this count.
Many implementations include an event
which can be used for this purpose; some CPUs do not (such
as Atom or Pentium D) and on some the event is unreliable
when HyperThreading is enabled (Nehalem)~\cite{segulja:pc2012}.
When no interrupt event is available it is 
possible (at least on Linux) to use values from
{\tt /proc/interrupts} instead (although this adds additional error and 
may count interrupts that happen outside of process context).

Compensation becomes more difficult when using hardware counters
in overflow or sampling mode (as is often used in performance
analysis or deterministic threading).  
Users may want hardware to signal an interrupt
after {\em exactly} one million retired instructions; aggregate
compensation methods will not work in this case.
One workaround
for this is described in the ReVirt project~\cite{dunlap+:osdi02};
they set the counter to overflow at a value before the value wanted,
adjust the count to be accurate, and then slowly single step the 
program until the desired count occurs.

\subsection{Dynamic Binary Instrumentation Results}

To aid in determining expected instruction counts, as well as 
determining per-opcode instruction frequency, we 
used various dynamic binary 
instrumentation (DBI) tools.  
These tools are used in program 
analysis and are capable of measuring program execution at a per-instruction
level; ideally the counts generated will match actual hardware.

We evaluate Pin~\cite{luk+:pldi05} version 2.8-33586,
the {\tt exp-bbv} and {\tt cachegrind} tools that come
with Valgrind~\cite{nethercote+:pldi07} version 3.8, 
and a current git checkout of Qemu~\cite{bellard:usenix2005}
that is patched to generate instruction statistics.      

Initial results did not match expected values; this is
because all of the DBI tools report string instructions with
a {\tt rep} repeat prefix as
having a count equivalent to the times repeated; this contrasts
with real hardware which reports {\tt rep}-prefixed string instruction as 
only one instruction.
We have modified the tools to take this into account, and for 
Pin the results for the assembly benchmark match the expected
values exactly.  

We were unable to fully
evaluate Valgrind as it currently does not handle numerous
infrequent instructions that are not generated by gcc 
but are generated by our test.  
Qemu works well,
but the patches needed for it to generate counts are intrusive and
make it a poor candidate for this type of analysis.

%
% Full-sized
%

\subsection{Full-sized benchmarks}

% SPEC CPU Retired Instructions

\begin{table*}[!htbp]
\caption{Measured Core2 retired instructions for SPEC CPU 2000.}
\label{table:spec2k_instructions}
\centering
\input{tables/spec2k_instructions}
\end{table*}

% SPEC CPU 2000 Retired Stores

\begin{table*}[!htbp]
\caption{Measured Core2 retired stores for SPEC CPU 2000.}
\label{table:spec2k_stores}
\centering
\input{tables/spec2k_stores}
\end{table*}

We apply our methods to the SPEC CPU 2000~\cite{spec:cpu00} benchmarks
and investigate how much variation is found in ``real-world''
applications.  We compile these programs statically
using gcc 4.3 and the {\tt -O3 -sse3} compiler options.
We run on a Core2 machine with a perf\_event enabled kernel.
SPEC CPU 2000 is out-dated compared to more recent benchmarks, but
it provides enough runtime to show any variations without 
completely overwhelming analysis with orders of magnitude larger
instruction counts.

Care is made to turn off address layout randomization and attempt to 
set the environment up in an exacting way previously shown to 
minimize run-to-run variations~\cite{weaver+:iiswc08}.
Despite these precautions, some variation is caused by the Pin DBI tool, 
as it adds various environment variables.

Table~\ref{table:spec2k_instructions} shows results for retired 
instructions on 
each benchmark, with the reference Pin result, the adjusted measured
value, and the difference between the two.  Likewise,
Table~\ref{table:spec2k_stores} shows results for retired stores, which
is deterministic on Core2.
The results show large divergences that are still under investigation,
although some seem to be related to {\tt malloc()} and
{\tt strlen()} being non-deterministic at runtime.

It is extremely difficult to track down the causes of divergences in 
benchmarks this large, so new methodologies need to be designed
to analyze these kinds of problems.  This will be even more
difficult when analyzing parallel applications.
